\babel@toc {english}{}
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces Distance values of 10 pairs of documents calculated in topic models with 100-to-2000 dimensions. The Kullback-Liebler(a), Jensen-Shannon Divergence(b), Hellinger(c) and S2JSD(c) metrics are considered.\relax }}{17}{figure.caption.6}% 
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces Research dimensions of the thesis. The first ones must be overcome before reaching higher dimensions. \relax }}{31}{figure.caption.9}% 
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces Topic model life-cycle. First texts are processed to retrieve tokens and build bags-of-words (BoW). They are then used to train a model that identifies patterns among words and builds topics. The model, which is also enabled to make inferences in unseen texts, is published as a service in an online repository. Finally, the service is used as resource in a particular solution, for example to categorize documents.\relax }}{36}{figure.caption.11}% 
\contentsline {figure}{\numberline {4.2}{\ignorespaces Representation of two scientific papers published at the International Conference on Knowledge Capture (K-CAP, 2019) that mention the same entity, \textit {Wordnet}, in different sections.\relax }}{38}{figure.caption.12}% 
\contentsline {figure}{\numberline {4.3}{\ignorespaces Relation between \textit {domain} and \textit {document}.\relax }}{39}{figure.caption.13}% 
\contentsline {figure}{\numberline {4.4}{\ignorespaces Relation between \textit {document} and \textit {snippet}.\relax }}{40}{figure.caption.14}% 
\contentsline {figure}{\numberline {4.5}{\ignorespaces Relation between \textit {annotations} and other resources.\relax }}{42}{figure.caption.15}% 
\contentsline {figure}{\numberline {4.6}{\ignorespaces Resource states.\relax }}{43}{figure.caption.16}% 
\contentsline {figure}{\numberline {4.7}{\ignorespaces Modules (in green) publishing or receiving events from the messenger service (in purple).\relax }}{44}{figure.caption.17}% 
\contentsline {figure}{\numberline {4.8}{\ignorespaces Sequence of \textit {events} exchanged between modules to create a topic model from the \textit {documents} added to a \textit {domain}.\relax }}{46}{figure.caption.18}% 
\contentsline {figure}{\numberline {4.9}{\ignorespaces Swagger-based web interface of a probabilistic topic model service created with \textit {librAIry}.\relax }}{48}{figure.caption.19}% 
\addvspace {10\p@ }
\contentsline {figure}{\numberline {5.1}{\ignorespaces Internal and External Representativeness. \relax }}{57}{figure.caption.22}% 
\contentsline {figure}{\numberline {5.2}{\ignorespaces Experiment to analyze the ability of topic-based representations to create relations from summaries \textit {vs} full-texts. \relax }}{58}{figure.caption.23}% 
\contentsline {figure}{\numberline {5.3}{\ignorespaces length of summaries\relax }}{60}{figure.caption.24}% 
\contentsline {figure}{\numberline {5.4}{\ignorespaces length of text parts\relax }}{60}{figure.caption.24}% 
\contentsline {figure}{\numberline {5.5}{\ignorespaces number of pairwises by similarity score (rounded up to two decimals)\relax }}{62}{figure.caption.26}% 
\contentsline {figure}{\numberline {5.6}{\ignorespaces topics per article with value above 0.5\relax }}{62}{figure.caption.26}% 
\contentsline {figure}{\numberline {5.7}{\ignorespaces Precision at different similarity thresholds\relax }}{63}{figure.caption.27}% 
\contentsline {figure}{\numberline {5.8}{\ignorespaces Recall at different similarity thresholds\relax }}{63}{figure.caption.27}% 
\contentsline {figure}{\numberline {5.9}{\ignorespaces f-measure performance\relax }}{63}{figure.caption.28}% 
\contentsline {figure}{\numberline {5.10}{\ignorespaces f-measure deviation\relax }}{63}{figure.caption.28}% 
\contentsline {figure}{\numberline {5.11}{\ignorespaces Probabilistic Topic Models, and in particular Latent Dirichlet Allocation (LDA), can efficiently divide the search space and speed up the process of finding relations among documents inside big collections.\relax }}{65}{figure.caption.29}% 
\contentsline {figure}{\numberline {5.12}{\ignorespaces TDC considers variations across consecutive topics inside a document\IeC {\textquoteright }s topic distribution.\relax }}{67}{figure.caption.30}% 
\contentsline {figure}{\numberline {5.13}{\ignorespaces RDC only considers the top n topics from the ranked list of probability distributions.\relax }}{68}{figure.caption.31}% 
\contentsline {figure}{\numberline {5.14}{\ignorespaces CRDC only considers the top n topics until the sum of the weights of the highest topics exceeded a given threshold.\relax }}{69}{figure.caption.32}% 
\contentsline {figure}{\numberline {5.15}{\ignorespaces Similarity values grouped by frequency in AIES\relax }}{70}{figure.caption.33}% 
\contentsline {figure}{\numberline {5.16}{\ignorespaces Effectiveness (JS-based) in AIES\relax }}{73}{figure.caption.34}% 
\contentsline {figure}{\numberline {5.17}{\ignorespaces Effectiveness (He-based) in AIES\relax }}{73}{figure.caption.34}% 
\contentsline {figure}{\numberline {5.18}{\ignorespaces Clusters in AIES\relax }}{74}{figure.caption.35}% 
\contentsline {figure}{\numberline {5.19}{\ignorespaces Cost (JS-based) in AIES\relax }}{76}{figure.caption.40}% 
\contentsline {figure}{\numberline {5.20}{\ignorespaces Cost (He-based) in AIES\relax }}{76}{figure.caption.40}% 
\contentsline {figure}{\numberline {5.21}{\ignorespaces Efficiency (JS-based) in AIES\relax }}{76}{figure.caption.41}% 
\contentsline {figure}{\numberline {5.22}{\ignorespaces Efficiency (He-based) in AIES\relax }}{76}{figure.caption.41}% 
\contentsline {figure}{\numberline {5.23}{\ignorespaces Similarity values grouped by frequency in DRM\relax }}{77}{figure.caption.42}% 
\contentsline {figure}{\numberline {5.24}{\ignorespaces Effectiveness (JS based) in DRM\relax }}{77}{figure.caption.43}% 
\contentsline {figure}{\numberline {5.25}{\ignorespaces Effectiveness (JS based) in DRM2\relax }}{77}{figure.caption.43}% 
\addvspace {10\p@ }
\contentsline {figure}{\numberline {6.1}{\ignorespaces Hash method based on hierarchical set of topics from a given topic distribution\relax }}{83}{figure.caption.44}% 
\contentsline {figure}{\numberline {6.2}{\ignorespaces Threshold-based Hierarchical Hash (L=3)\relax }}{86}{figure.caption.45}% 
\contentsline {figure}{\numberline {6.3}{\ignorespaces Centroid-based Hierarchical Hash (L=3)\relax }}{87}{figure.caption.46}% 
\contentsline {figure}{\numberline {6.4}{\ignorespaces Density-based Hierarchical Hash (L=3)\relax }}{88}{figure.caption.47}% 
\contentsline {figure}{\numberline {6.5}{\ignorespaces Topic Distribution of two documents. Similarity score, based on JSD, is equals to 0.74\relax }}{89}{figure.caption.48}% 
\contentsline {figure}{\numberline {6.6}{\ignorespaces Topic Distribution of two documents. Similarity score, based on JSD, is equals to 0.71\relax }}{89}{figure.caption.49}% 
\contentsline {figure}{\numberline {6.7}{\ignorespaces Precision at 5 (\textit {mean}) of threshold-based hashing method when number of topics varies in CORDIS dataset.\relax }}{98}{figure.caption.62}% 
\contentsline {figure}{\numberline {6.8}{\ignorespaces Precision at 5 (\textit {mean}) of centroid-based hashing method when number of topics varies in CORDIS dataset.\relax }}{99}{figure.caption.63}% 
\contentsline {figure}{\numberline {6.9}{\ignorespaces Precision at 5 (\textit {mean}) of density-based hashing method when number of topics varies in CORDIS dataset.\relax }}{99}{figure.caption.64}% 
\contentsline {figure}{\numberline {6.10}{\ignorespaces Most relevant topics in similar documents from using a document as query (Q1) and setting topic t10 as mandatory (Q2).\relax }}{100}{figure.caption.66}% 
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
