\babel@toc {english}{}
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {table}{\numberline {2.1}{\ignorespaces Number of words and tokens of publications listed in Section \ref {sec:publications} when preprocessed.\relax }}{15}{table.caption.5}% 
\contentsline {table}{\numberline {2.2}{\ignorespaces Probabilistic topics created from the collection of articles listed in Section \ref {sec:publications}. For each topic the five most representative words are shown together with their normalized relevance (0-1000).\relax }}{19}{table.caption.7}% 
\contentsline {table}{\numberline {2.3}{\ignorespaces Topic distributions based on the LDA model described in table \ref {table:sample-topics}.\relax }}{22}{table.caption.9}% 
\contentsline {table}{\numberline {2.4}{\ignorespaces Kullback-Liebler divergences between the topic distributions from Table \ref {table:sample-doctopics}. There are two values per pair because it is not symmetric.\relax }}{23}{table.caption.10}% 
\contentsline {table}{\numberline {2.5}{\ignorespaces Jensen-Shannon divergences between the topic distributions from Table \ref {table:sample-doctopics}.\relax }}{24}{table.caption.11}% 
\contentsline {table}{\numberline {2.6}{\ignorespaces Hellinger distances between the topic distributions from Table \ref {table:sample-doctopics}.\relax }}{26}{table.caption.12}% 
\contentsline {table}{\numberline {2.7}{\ignorespaces S2JSD distances between the topic distributions from Table \ref {table:sample-doctopics}.\relax }}{27}{table.caption.13}% 
\contentsline {table}{\numberline {2.8}{\ignorespaces Research areas and limitations.\relax }}{28}{table.caption.14}% 
\contentsline {table}{\numberline {2.9}{\ignorespaces Research areas and proposals.\relax }}{36}{table.caption.17}% 
\addvspace {10\p@ }
\contentsline {table}{\numberline {3.1}{\ignorespaces Hypotheses and research dimensions.\relax }}{41}{table.caption.18}% 
\contentsline {table}{\numberline {3.2}{\ignorespaces Open Research Challenges and Hypotheses.\relax }}{45}{table.caption.19}% 
\contentsline {table}{\numberline {3.3}{\ignorespaces Research and technical objectives and their related challenges.\relax }}{49}{table.caption.21}% 
\addvspace {10\p@ }
\contentsline {table}{\numberline {4.1}{\ignorespaces Potential uses of a topic model.\relax }}{64}{table.caption.31}% 
\contentsline {table}{\numberline {4.2}{\ignorespaces Operations offered by a topic model-as-a-service to cover potential tasks.\relax }}{66}{table.caption.32}% 
\addvspace {10\p@ }
\contentsline {table}{\numberline {5.1}{\ignorespaces Accuracy results when comparing the most related articles using a summary (e.g. abstract, approach, background, challenge, future work or outcome), with those obtained using the full-text of the article (\textit {internal-representativeness}).\relax }}{78}{table.caption.37}% 
\contentsline {table}{\numberline {5.2}{\ignorespaces Precision (JS-based) in AIES\relax }}{92}{table.caption.52}% 
\contentsline {table}{\numberline {5.3}{\ignorespaces Precision (He-based) in AIES\relax }}{93}{table.caption.53}% 
\contentsline {table}{\numberline {5.4}{\ignorespaces Recall (JS-based) in AIES\relax }}{93}{table.caption.54}% 
\contentsline {table}{\numberline {5.5}{\ignorespaces Recall (He-based) in AIES\relax }}{94}{table.caption.55}% 
\addvspace {10\p@ }
\contentsline {table}{\numberline {6.1}{\ignorespaces Precision at 5 (\textit {mean} and \textit {median}) of threshold-based (THHM), centroid-based (CHHM) and density-based (DHHM) hierarchical hashing methods on Open Research dataset using a model with 100 topics. LEVEL column indicates the number of hierarchies used.\relax }}{111}{table.caption.69}% 
\contentsline {table}{\numberline {6.2}{\ignorespaces Precision at 5 (\textit {mean} and \textit {median}) of threshold-based (THHM), centroid-based (CHHM) and density-based (DHHM) hierarchical hashing methods on Open Research dataset using a model with 500 topics. LEVEL column indicates the number of hierarchies used.\relax }}{111}{table.caption.70}% 
\contentsline {table}{\numberline {6.3}{\ignorespaces Precision at 5 (\textit {mean} and \textit {median}) of threshold-based (THHM), centroid-based (CHHM) and density-based (DHHM) hierarchical hashing methods on CORDIS dataset using a model with 70 topics. LEVEL column indicates the number of hierarchies used.\relax }}{112}{table.caption.71}% 
\contentsline {table}{\numberline {6.4}{\ignorespaces Precision at 5 (\textit {mean} and \textit {median}) of threshold-based (THHM), centroid-based (CHHM) and density-based (DHHM) hierarchical hashing methods on CORDIS dataset using a model with 150 topics. LEVEL column indicates the number of hierarchies used.\relax }}{112}{table.caption.72}% 
\contentsline {table}{\numberline {6.5}{\ignorespaces Precision at 5 (\textit {mean} and \textit {median}) of threshold-based (THHM), centroid-based (CHHM) and density-based (DHHM) hierarchical hashing methods on Patents dataset using a model with 250 topics. LEVEL column indicates the number of hierarchies used.\relax }}{114}{table.caption.73}% 
\contentsline {table}{\numberline {6.6}{\ignorespaces Precision at 5 (\textit {mean} and \textit {median}) of threshold-based (THHM), centroid-based (CHHM) and density-based (DHHM) hierarchical hashing methods on Patents dataset using a model with 750 topics. LEVEL column indicates the number of hierarchies used.\relax }}{114}{table.caption.74}% 
\contentsline {table}{\numberline {6.7}{\ignorespaces Data size ratio used (\textit {mean} and \textit {median}) of threshold-based (THHM), centroid-based (CHHM) and density-based (DHHM) hierarchical hashing methods on Open Research dataset and 100 topics.\relax }}{115}{table.caption.75}% 
\contentsline {table}{\numberline {6.8}{\ignorespaces Data size ratio used (\textit {mean} and \textit {median}) of threshold-based (THHM), centroid-based (CHHM) and density-based (DHHM) hierarchical hashing methods on Open Research dataset and 500 topics.\relax }}{115}{table.caption.76}% 
\contentsline {table}{\numberline {6.9}{\ignorespaces Data size ratio used (\textit {mean} and \textit {median}) of threshold-based (THHM), centroid-based (CHHM) and density-based (DHHM) hierarchical hashing methods on CORDIS dataset and 70 topics.\relax }}{116}{table.caption.77}% 
\contentsline {table}{\numberline {6.10}{\ignorespaces Data size ratio used (\textit {mean} and \textit {median}) of threshold-based (THHM), centroid-based (CHHM) and density-based (DHHM) hierarchical hashing methods on CORDIS dataset and 150 topics.\relax }}{116}{table.caption.78}% 
\contentsline {table}{\numberline {6.11}{\ignorespaces Data size ratio used (\textit {mean} and \textit {median}) of threshold-based (THHM), centroid-based (CHHM) and density-based (DHHM) hierarchical hashing methods on Patents dataset and 250 topics.\relax }}{117}{table.caption.79}% 
\contentsline {table}{\numberline {6.12}{\ignorespaces Data size ratio used (\textit {mean} and \textit {median}) of threshold-based (THHM), centroid-based (CHHM) and density-based (DHHM) hierarchical hashing methods on Patents dataset and 750 topics.\relax }}{117}{table.caption.80}% 
\contentsline {table}{\numberline {6.13}{\ignorespaces Number of documents related to a given one (q1) and also in a specific domain (q2) for threshold-based (thhm), centroid-based (chhm) and density-based (dhhm) hierarchical hashing methods.\relax }}{120}{table.caption.84}% 
\addvspace {10\p@ }
\contentsline {table}{\numberline {7.1}{\ignorespaces Randonly selected theme-aligned topics described by top 10 words based on EUROVOC annotations from JRC-Acquis dataset\relax }}{130}{table.caption.88}% 
\contentsline {table}{\numberline {7.2}{\ignorespaces Document classification performance (precision-'prec', recall-'rec' and fMeasure-'f1') of the categories-based (\textit {cat}) and synset-based (\textit {syn}) topic alignment algorithms in monolingual document collections\relax }}{133}{table.caption.90}% 
\contentsline {table}{\numberline {7.3}{\ignorespaces Document classification performance (precision-'prec', recall-'rec' and fMeasure-'f1') of the categories-based (\textit {cat}) and synset-based (\textit {syn}) topic alignment algorithms in multi-lingual document collections\relax }}{134}{table.caption.91}% 
\contentsline {table}{\numberline {7.4}{\ignorespaces Information retrieval performance (precision@3, precision@5 and precision@10) of the categories-based (\textit {cat}) and synset-based (\textit {syn}) topic alignment algorithms in monolingual document collections\relax }}{135}{table.caption.92}% 
\contentsline {table}{\numberline {7.5}{\ignorespaces Information retrieval performance (precision@3, precision@5 and precision@10) of the categories-based (\textit {cat}) and synset-based (\textit {syn}) topic alignment algorithms in multi-lingual document collections\relax }}{135}{table.caption.93}% 
\contentsline {table}{\numberline {7.6}{\ignorespaces Number of documents and tokens by dataset\relax }}{136}{table.caption.95}% 
\contentsline {table}{\numberline {7.7}{\ignorespaces Aggregated MAP results by metric and model\relax }}{138}{table.caption.97}% 
\contentsline {table}{\numberline {7.8}{\ignorespaces MAP results by dividing the corpus into three equal subsets to train and evaluate the models in English(\textit {en}) and Spanish(\textit {es})\relax }}{139}{table.caption.98}% 
\contentsline {table}{\numberline {7.9}{\ignorespaces MAP results by dividing the corpus into six equal subsets to train and evaluate the models in English(\textit {en}) and Spanish(\textit {es})\relax }}{140}{table.caption.99}% 
\contentsline {table}{\numberline {7.10}{\ignorespaces MAP results by dividing the corpus into nine equal subsets to train and evaluate the models in English(\textit {en}) and Spanish(\textit {es})\relax }}{141}{table.caption.100}% 
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {table}{\numberline {9.1}{\ignorespaces Assumptions considered in this thesis.\relax }}{157}{table.caption.108}% 
\contentsline {table}{\numberline {9.2}{\ignorespaces Restrictions considered in this thesis.\relax }}{157}{table.caption.109}% 
