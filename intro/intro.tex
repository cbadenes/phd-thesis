
% this file is called up by thesis.tex
% content in this file will be fed into the main document

%: ----------------------- introduction file header -----------------------
\chapter{Introduction}\label{ch:introduction}

\graphicspath{{introduction/figures/}}

% -------------------------------------------------------------
% -- Introduction
% -------------------------------------------------------------

% Motivation: 
% - Presentar el problema general y las soluciones propuestas por la tesis (enfoque top-down), en vez del enfoque técnico actual (bootom-up)
% - Buscar referencias que hablen del número de docs que se generan cada día, o cosas similares
% - Hablar de knowledge-intensive task, o de knowledge-workers, o similar

%%% <-- present the motivation

% huge data (https://www.nature.com/articles/nj7612-457a)
% large-scale
% Around 8 TB of textual data are consumed everyday by electronic media. 
% https://curia.europa.eu/jcms/upload/docs/application/pdf/2020-05/ra_pan_2019_interieur_en_final.pdf
Huge amounts of textual documents are produced daily in digital format. More than two thousand blog entries are published, nine thousand tweets are written, and more than two million emails are sent on the Internet every second in 2021\footnote{https://www.internetlivestats.com/one-second}. The number of scientific publications per year  increased by 8-9\%~in the last decade \citep{Ware2018STM}. More than one million papers, about two per minute,  were submitted to the PubMed database, the leading database of references and abstracts on life sciences and biomedical research, during 2018. The behavior is similar in other domains. More than 168,000 procedural documents and 3,000 judicial notices were published in the Official Journal of the European Union\footnote{\url{https://eur-lex.europa.eu/oj/direct-access.html}} in 2019. Furthermore, unlike the academic domain where articles are mostly published in English, legal documents are usually available in multiple languages. The Court of Justice of the European Union\footnote{\url{https://curia.europa.eu}} had to translate in 2019 over 1 million texts into its 24 official languages, with 552 possible language combinations, in just one year. These numbers make it difficult for an expert in the academic or legal domains to stay abreast by only reading a few articles nowadays. Navigating the growing torrent of textual data and exploring their content is not only necessary, but has become a crucial activity that experts must add to their daily tasks. 

Document retrieval techniques are being used nowadays to facilitate text review in such big collections. Major digital publishers specialized in scientific\footnote{\url{https://www.nature.com}}, technical\footnote{\url{https://www.elsevier.com}}, and medical\footnote{\url{https://pubmed.ncbi.nlm.nih.gov}} content provide search engines that make it easier to browse their collections of digital articles. Given a few keywords, a list of relevant papers is retrieved and offered for reading. Legal documents are also exploited through similar solutions. The Spanish\footnote{\url{https://www.oepm.es}}, American\footnote{\url{https://www.uspto.gov/}} and European\footnote{\url{https://www.epo.org}} intellectual property registration offices, for example, allow exploring their patent collections by search engines guided by keywords and/or categories. These categories are based on the International Patent Classification (IPC) system and are available thanks to the manual annotation of their authors and of patent officers. This classification contains approximately 70,000 codes for different technical areas. This label-based browsing has been also adopted by other academic search engines\footnote{\url{https://academic.microsoft.com}} to organize papers by research areas, or even by evaluation tasks to cover the state-of-the-art methods\footnote{\url{https://paperswithcode.com}}. A domain such as natural language processing, for example, is organized into 256 categories such as 'knowledge representation', 'question-answering', 'machine translation' and so on. However, the use of tags to categorize scientific papers is still insufficient and some additional text processing tasks are required to homogenize the format and criteria of the article labels. One of the main reasons that limits a widespread use is the \textit{difficulty to identify labels that describe a research work in sufficient detail}.

% A new research field or category appear?
Furthermore, not all approaches can assume that new categories will emerge. \textit{Searches guided by keywords or tags are useful when the domain is known, but when new categories appear these mechanisms are insufficient}. In scientific domains, a way to identify new research areas is through peer review processes. There are also reports that identify the hottest and emerging specialty areas in scientific research from the last years\footnote{\url{https://discover.clarivate.com/ResearchFronts2019_EN}}. The methodology used in these reports assumes that cumulatively, and over time, citations in research leave a trail that highlights progress and advancements across a range of fields. By regularly tracking these citations and unpacking the patterns and groupings of how papers are cited, in particular clusters of papers that are frequently cited together, new research areas take shape. Such reports also exist on patent collections to discover technology trends\footnote{\url{https://www.wipo.int/tech_trends}}.

In this context, identifying relationships between documents is key to know their information and facilitate their exploration. A documentary exploration does not stop when a relevant article is found, but starts from its content shaping the area of interest through its relations. Most academic\footnote{\url{https://www.semanticscholar.org}} and legal\footnote{\url{https://patents.google.com}} search engines provide a list of related documents for each text and offer navigating through them. The relationship between two documents can be based on references, when documents are cited by others\footnote{\url{http://citationgecko.com}}, or content, when documents share a thematic area. The chains of articles derived from that related content can lead to more complex structures when cross-relations are considered. A document can be related to another that, in turn, is related to a third one that can be also related to the first article. This content-guided exploration helps browsing document collections by areas of interest not necessarily aligned with a list of predefined categories. A visual overview of an academic field, for example, can be provided by showing graphs of articles with similar content\footnote{\url{https://www.connectedpapers.com}}.

While these initiatives are valuable efforts to address access to huge amounts of documents, they are still insufficient to make the most out of the knowledge available within the textual collection. Two types of inferences are needed: \textit{bottom-up}, from documents to collections, and \textit{top-down}, from document relationships to texts. The knowledge derived from a text comes from the concepts evoked by its words \citep{Griffiths2007}, and the knowledge derived from a document collection emerges from the relationships between its texts \citep{Kenter2015}. Both require understanding the meaning, the semantics, of texts at different levels. \textit{Semantic awareness is desirable to interpret the relationships and guide the exploration}. The focus is on why some texts are related and what concepts are key to those relationships. But analyzing and comparing texts on a large scale also requires addressing some challenges imposed by external conditions that have appeared in recent years:
\begin{itemize}
\item \textbf{Complexity}: The increasing variety of themes, in ever growing collections, has forced a reconsideration of the way to compare their documents. The operations required to compute each comparison should be simplified as much as possible.
\item \textbf{Efficiency}: The algorithms, besides being accurate enough, must be also efficient in order to be applied on a large scale. Brute-force techniques cannot be applied to compare all items in a huge corpus.
\item \textbf{Explainability}: The relations among documents must be explained in such a way that provide knowledge about the content of the texts. It is not enough that one text is related to another, it is necessary to explain why it is so. 
\item \textbf{Multilinguality}: The increasing availability of texts written in different natural languages also makes it necessary to address comparison in multilingual collections. External translation systems cannot been considered as the only applicable solution, since they increase processing costs and potentially introduce a bias in the relationships that are obtained. Solutions that relate texts without translating them are desirable.
\end{itemize}

In our work we aim at \textbf{facilitating the exploration of huge collections of documents written in multiple languages}. We address the problem of comparing them on a large scale while enabling a semantic-aware exploration through their content. Our proposal automatically discovers thematic associations between texts using probabilistic models to describe their content through topics, and organizes document collections so that they can be efficiently and transparently browsed through the related content regardless of their language.

\section{Contributions}

The following contributions are presented in this thesis:

\begin{itemize}
\item \textbf{A Scalable Framework for Probabilistic Topic Modeling}: We design and implement a text processing model that supports the creation of probabilistic topic models by distributing operations among functional units. Based on this abstraction, we implement a framework that becomes the foundation of this thesis research, which is used as a tool for supporting performance analysis and algorithm design.
\item \textbf{A Publishing Model for Probabilistic Topic Models}: We propose a unified form to publish and (re)use topic models as Web services that are available from online repositories, so as to facilitate the exploitation of probabilistic topic models.
\item \textbf{Hierarchical Thematic Annotations for High-dimensional Topic Models}: To study the problem of representativeness in high dimensional topic models, we exploit the relationships between texts derived from their topic distributions. We show how the distances vary between the same texts when the dimensions of the model change, and how less representative topics can influence their calculation. Our analytical and experimental results show that \textit{the more topics are available in the model, the less representative are the distance measurements based on densities}. We identify hierarchies in the topic distributions that maintain their representativeness regardless of the dimensionality of the model, and without losing the ability to measure distances. We propose a method to annotate texts using topic hierarchies, and a distance metric based on these hierarchical representations.
\item \textbf{Support for Large-scale Document Similarity Comparisons}: We present an efficient mechanism to index and retrieve related documents using hierarchical annotations. It facilitates the exploration of a collection by the themes inferred from its texts.
\item \textbf{Identify Cross-lingual Document Relations}: We introduce a technique to transform probabilistic topics from different languages into a single representation space based on shared concepts where texts can be thematically related regardless of the language used.
\end{itemize}

\section{Thesis Structure}

The thesis is structured as follows:

\textit{Chapter \ref{ch:soa}} describes the main concepts handled throughout the thesis, analyses the state of the art and identifies the main limitations. \textit{Chapter \ref{ch:hypothesis}} presents the research problems and hypotheses that guide our work, as well as assumptions and restrictions and details the methodology that has been followed in this research. \textit{Chapter \ref{ch:scalability}} describes the software architecture proposed to analyze huge document collections and the format suggested to distribute and reuse the topic models built in this thesis. \textit{Chapter \ref{ch:explainability}} details our proposed text annotation algorithm to organize probabilistic topics into hierarchical levels according to their relevance. \textit{Chapter \ref{ch:comparisons}} shows how to store and search documents efficiently from large collections when they are annotated with topic hierarchies.  \textit{Chapter \ref{ch:multilinguality}} explains the method to relate multilingual texts from their main topics without requiring any prior knowledge between the languages. \textit{Chapter \ref{ch:experiments}} describes real-world projects where the results from this thesis have been used. Finally, \textit{Chapter \ref{ch:conclusion}} presents the conclusions and introduce the future lines of work. Where relevant, evaluations have been included in the corresponding chapters where the specific contributions are presented.


\section{Publications}

The following publications support the research work presented in this thesis:

% relacionar los papers a los capítulos, en vez de orden cronológico.

\begin{itemize}
\item \textbf{Chapter \ref{ch:scalability}: Creation and Publication of Probabilistic Topic Models}:
\begin{itemize}
\item \textit{\textbf{Carlos Badenes-Olmedo}, José Luis Redondo-Garcia, and Oscar Corcho. \textit{Distributing Text Mining tasks with librAIry}. Proceedings of the 17th ACM Symposium on Document Engineering (DocEng). Association for Computing Machinery, Valletta, Malta. 2017.} This is the key paper describing the architecture and technological features of librAIry, our framework for processing texts and creating probabilistic topic models. 
\item \textit{Victoria Kosa, Alyona Chugunenko, Eugene Yuschenko, \textbf{Carlos Badenes-Olmedo}, Vadim Ermolayev, and Aliaksandr Birukou. \textit{Semantic saturation in retrospective text document collections}. Information and Communication Technologies in Education, Research, and Industrial Applications (ICTERI) PhD Symposium, vol. 1851, pages 1-8. CEUR-WS. 2017.} The work presented in this paper makes use of the text-processing module proposed by librAIry to retrieve multi-word terms from a document collection.
\item \textit{Victoria Kosa, David Chaves-Fraga, Dmitriy Naumenko, Eugene Yuschenko, \textbf{Carlos Badenes-Olmedo}, Vadim Ermolayev, Aliaksandr Birukou, Nick Bassiliades, Hans-Georg Fill, Vitaliy Yakovyna, Heinrich C. Mayr, Mykola Nikitchenko, Grygoriy Zholtkevych, and Aleksander Spivakovsky. \textit{Cross-Evaluation of Automated Term Extraction Tools by Measuring Terminological Saturation}. Information and Communication Technologies in Education, Research, and Industrial Applications, pages 135-163. Springer International Publishing. 2018.} The distributed document processing and representation model used by librAIry is improved during this work to support the extraction of the most relevant terms from a collection of scientific articles.
\end{itemize}
\item \textit{Chapter \ref{ch:explainability}- Explainable Topic-based Associations}:
\begin{itemize}
\item \textbf{Carlos Badenes-Olmedo}, José Luis Redondo-García, and Oscar Corcho. \textit{Efficient Clustering from Distributions over Topics}. Proceedings of the 9th International Conference on Knowledge Capture (K-CAP), Article 17, 1–8. Association for Computing Machinery, Austin, TX, USA. 2017. This article provides the basis for transforming probabilistic topic distributions into expressions that group similar content. 
\item \textbf{Carlos Badenes-Olmedo}, Jose Luis Redondo-Garcia, and Oscar Corcho. \textit{An initial Analysis of Topic-based Similarity among Scientific Documents based on their Rhetorical Discourse Parts}. Proceedings of the 1st Workshop on Enabling Open Semantic Science (SemSci) co-located with 16th International Semantic Web Conference (ISWC 2017), 15-22. Vienna, Austria. 2017. This work demonstrates the need to use full texts to relate content from their topic distributions, since the use of abstracts of scientific texts is shown to be less accurate than other longer sections. 
\end{itemize}
\item \textbf{Chapter \ref{ch:comparisons}: Large-scale Comparisons of Topic Distributions}:
\begin{itemize}
\item \textit{\textbf{Carlos Badenes-Olmedo}, José Luis Redondo-García, and Oscar Corcho. \textit{Large-scale Semantic Exploration of Scientific Literature Using Topic-based Hashing Algorithms}. Semantic Web, vol. 11, no. 5, pp. 735-750. 2020.} This paper describes the key algorithm of this thesis to reduce probabilistic topic distributions into hierarchical expressions that relate similar content without losing topic information.
%\item Borja Lozano, \textbf{Carlos Badenes-Olmedo} and Oscar Corcho. Hierarchical representations of topics to uncover the underlying knowledge of semantically related texts. Proceedings of the 22nd International Conference on Knowledge Engineering and Knowledge Management (EKAW), (under revision). 2020
\end{itemize}
\item \textbf{Chapter \ref{ch:multilinguality}: Cross-lingual Document Similarity}:
\begin{itemize}
\item \textit{\textbf{Carlos Badenes-Olmedo}, José Luis Redondo-García, and Oscar Corcho. \textit{Scalable Cross-lingual Document Similarity through Language-specific Concept Hierarchies}. Proceedings of the 10th International Conference on Knowledge Capture (K-CAP). Association for Computing Machinery, 147–153. Marina Del Rey, CA, USA. 2019.} In this paper we describe probabilistic topics using concept-based representations instead of words.  Multilingual topics are automatically aligned to create a single representation space across languages.   
\item \textit{\textbf{Carlos Badenes-Olmedo}, José Luis Redondo-García, and Oscar Corcho. \textit{Legal document retrieval across languages: topic hierarchies based on synsets}. Proceedings of the 1st Workshop on Iberlegal co-located with 32nd International Conference on Legal Knowledge and Information Systems organized by the Foundation for Legal Knowledge Based Systems (JURIX). Madrid, Spain. 2019.} The work presented in this paper evaluates the conceptual representation of multilingual topics to relate legal documents in several languages: English, Spanish, French and Portuguese.
\end{itemize}
\item \textbf{Chapter \ref{ch:experiments}: Experiments}:
\begin{itemize}
\item \textit{Beatriz López-Centeno, \textbf{Carlos Badenes-Olmedo}, Ángel Mataix-Sanjuan, Katie McAllister, José M Bellón, Sara Gibbons, Pascual Balsalobre, Leire Pérez-Latorre, Juana Benedí, Catia Marzolini, Ainhoa Aranguren-Oyarzábal, Saye Khoo, María J Calvo-Alcántara, Juan Berenguer. \textit{Polypharmacy and Drug-Drug Interactions in People Living With Human Immunodeficiency Virus in the Region of Madrid, Spain: A Population-Based Study}. Clinical Infectious Diseases. vol. 71,2, 353-362. 2020.} In this work we exploit the ability of librAIry to relate content described by hierarchical representations. In a medical domain, patients are grouped according to the drugs used in their treatments and their potential interactions.
\item \textit{Ahmet Soylu, Oscar Corcho, Brian Elvesaeter, \textbf{Carlos Badenes-Olmedo}, Francisco Yedro, Matej Kovacic, Matej Posinkovic, Ian Makgill, Chris Taggart, Elena Simperl, Till C. Lech, and Dumitru Roman. \textit{Enhancing Public Procurement in the European Union through Constructing and Exploiting an Integrated Knowledge Graph}. Proceedings of the 19th International Semantic Web Conference (ISWC). 2020.} This paper presents the work done to relate multilingual European regulations to public contracts through their hierarchical topic-based representations. A document search engine that leverages this facility is built.  
\item \textit{\textbf{Carlos Badenes-Olmedo}, David Chaves-Fraga, Maria Poveda-Villalon, Ana Iglesias-Molina, Pablo Calleja, Socorro Bernardos, Patricia Martín-Chozas, Alba Fernández-Izquierdo, Elvira Amador-Dominguez, Paola Espinoza-Arias, Luis Pozo, Edna Ruckhaus, Esteban Gonzalez-Guardia, Raquel Cedazo, Beatriz Lopez-Centeno, and Oscar Corcho. \textit{Drugs4Covid: Drug-driven Knowledge Exploitation based on Scientific Publications}. arXiv e-prints:2012.01953. 2020.} In the context of creating a knowledge graph describing the drugs used to treat COVID-19, this article shows the work to adapt librAIry to infer relationships between drugs from their mentions in scientific articles. 
\end{itemize}
\end{itemize}



